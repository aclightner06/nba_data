{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ef1f537-2f49-4384-b738-869e4c929613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "\n",
    "class NBA:\n",
    "    \"\"\"\n",
    "    NBA - Documentation goes here\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url, table_id, column_schema, row_schema, data_schema,\n",
    "                 use_links=[], add_links={}, add_links_to_text={}, name_change={}, filter_rows = {}, ):\n",
    "        self.url = url\n",
    "        self.table_id = table_id\n",
    "        self.use_links = use_links\n",
    "        self.add_links = add_links\n",
    "        self.column_schema = column_schema\n",
    "        self.row_schema = row_schema\n",
    "        self.data_schema = data_schema\n",
    "        self.name_change = name_change\n",
    "        self.filter_rows = filter_rows\n",
    "        self.add_links_to_text = add_links_to_text\n",
    "        \n",
    "        try:\n",
    "            # print('0')\n",
    "            self.get_soup()\n",
    "            # print('1')\n",
    "            self.get_columns()\n",
    "            # print('2')\n",
    "            self.get_rows()    \n",
    "            # print('3')\n",
    "            self.get_data()\n",
    "            # print('4')\n",
    "            self.add_link()\n",
    "            # print('5')\n",
    "            self.add_link_to_text()\n",
    "            # print('5.5')\n",
    "            self.filter_by_value()\n",
    "            # print('6')\n",
    "        except:\n",
    "            # print('error')\n",
    "            self.df = pd.DataFrame()\n",
    "\n",
    "    def get_soup(self):\n",
    "\n",
    "        r = requests.get(self.url)\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        self.soup = soup.find('table', {\"id\": self.table_id})\n",
    "        \n",
    "    def get_columns(self):\n",
    "\n",
    "        base=\"self.soup\"\n",
    "        add=\".findAll('{}'){}\"\n",
    "\n",
    "        for i in range(len(self.column_schema['column_attrs'])):\n",
    "            if self.column_schema['offset'][i] != None:\n",
    "                base = f\"{base}{add.format(self.column_schema['column_attrs'][i],'['+str(self.column_schema['offset'][i])+']')}\"\n",
    "            else:\n",
    "                base = f\"{base}{add.format(self.column_schema['column_attrs'][i],'')}\"\n",
    "\n",
    "        loop = f\"[x.getText() for x in {base}][{self.column_schema['shift']}:]\"\n",
    "\n",
    "        self.columns = eval(loop)\n",
    "\n",
    "        for k, v in self.name_change.items():\n",
    "            self.columns[k] = v   \n",
    "            \n",
    "    def get_rows(self):\n",
    "\n",
    "        base=\"self.soup\"\n",
    "        add=\".findAll('{}'){}\"\n",
    "\n",
    "        for i in range(len(self.row_schema['row_attrs'])):\n",
    "            if self.row_schema['row_offset'][i] != None:\n",
    "                base = f\"{base}{add.format(self.row_schema['row_attrs'][i], '['+str(self.row_schema['row_offset'][i])+']')}\"\n",
    "            else:\n",
    "                base = f\"{base}{add.format(self.row_schema['row_attrs'][i], '')}\"\n",
    "\n",
    "        self.rows = eval(base)\n",
    "\n",
    "    def get_data(self):\n",
    "\n",
    "        data = [[x.getText() if j not in self.use_links else x.a['href'] \\\n",
    "                 for j, x in enumerate(self.rows[i].findAll(self.data_schema['data_attrs']))][self.data_schema[\"data_offset\"]:] \\\n",
    "                for i in range(len(self.rows))]\n",
    "\n",
    "        max_list_len = max(list(map(lambda x: len(x), data)))\n",
    "        self.data = [self.pad_list(sub,max_list_len) for sub in data if len(sub) > 0]\n",
    "\n",
    "        self.df = pd.DataFrame(data=data, columns=self.columns).dropna(how='all').reset_index(drop=True)\n",
    "        \n",
    "    def add_link(self):\n",
    "\n",
    "        for key, value in self.add_links.items():\n",
    "            self.df[key] = [[x.a['href'] for j,x in enumerate(self.rows[i].findAll(self.data_schema['data_attrs'])) \\\n",
    "                             if j == value][0] for i in range(len(self.data))]\n",
    "            \n",
    "    def add_link_to_text(self):\n",
    "        \n",
    "        for key, value in self.add_links_to_text.items():\n",
    "                    \n",
    "            l1 = [[x.findAll('a') for i,x in enumerate(self.rows[j].findAll(self.data_schema['data_attrs'])) if i == value and x.a != None] \\\n",
    "                  for j in range(len(self.data))]\n",
    "                        \n",
    "            self.df[key] = [dict(zip(map(lambda z: z.getText(), x[0]), map(lambda z: z['href'], x[0]))) if len(x) > 0 else None for x in l1]\n",
    "            self.df[key] = self.df[key].astype(str)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def pad_list(self, l,n):\n",
    "        while len(l) < n:\n",
    "            l.append(\"\")\n",
    "        return l\n",
    "    \n",
    "    def filter_by_value(self):\n",
    "        for key, value in self.filter_rows.items():\n",
    "            self.df = self.df[self.df[key] != value].reset_index(drop=True)\n",
    "\n",
    "def pbp():\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "\n",
    "    boxscore_query = \"\"\"\n",
    "    WITH\n",
    "      pbp AS (\n",
    "      SELECT\n",
    "        DISTINCT boxscore\n",
    "      FROM\n",
    "        `dulcet-name-296415.nba_test.pbp_raw`),\n",
    "      sch AS (\n",
    "      SELECT\n",
    "        DISTINCT boxscore\n",
    "      FROM\n",
    "        `dulcet-name-296415.nba_test.schedule`)\n",
    "    SELECT\n",
    "      sch.boxscore\n",
    "    FROM\n",
    "      sch\n",
    "    LEFT JOIN\n",
    "      pbp\n",
    "    ON\n",
    "      sch.boxscore = pbp.boxscore\n",
    "    WHERE\n",
    "      pbp.boxscore IS NULL\n",
    "    ORDER BY\n",
    "      RAND()\n",
    "    LIMIT\n",
    "      10\n",
    "    \"\"\"\n",
    "\n",
    "    boxscores = client.query(boxscore_query).to_dataframe().boxscore.tolist()\n",
    "\n",
    "    url = \"https://www.basketball-reference.com{}\"\n",
    "\n",
    "    pbp_col_attrs = {\"column_attrs\": ['tr', 'th'], \"shift\": 0, \"offset\": ['1', None]}\n",
    "    pbp_row_attrs = {\"row_attrs\": ['tr'], \"row_offset\": ['2:']}\n",
    "    pbp_data_attrs = {\"data_attrs\": ['td'], \"data_offset\": 0}\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "\n",
    "    for box in boxscores:\n",
    "\n",
    "        temp_url = url.format(box.replace(\"boxscores\", \"boxscores/pbp\"))\n",
    "\n",
    "        pbp = NBA(url = temp_url, \n",
    "              table_id = 'pbp',\n",
    "              column_schema = pbp_col_attrs, \n",
    "              row_schema = pbp_row_attrs, \n",
    "              data_schema = pbp_data_attrs,\n",
    "              name_change={2:\"plus1\", 4:'plus2'},\n",
    "                 add_links_to_text={'tm1_players': 1, \"tm2_players\":5})\n",
    "\n",
    "\n",
    "        if len(pbp.df) > 0:\n",
    "            pbp.df['boxscore'] = box\n",
    "            pbp.df['tm1_name'] = pbp.df.columns[1]\n",
    "            pbp.df['tm2_name'] = pbp.df.columns[5]\n",
    "\n",
    "            pbp.df = pbp.df.rename(columns={pbp.df.columns[1]: 'tm1_play', pbp.df.columns[5]: 'tm2_play'})\n",
    "\n",
    "            out = pd.concat([out, pbp.df])\n",
    "        \n",
    "    schema = [\n",
    "        bigquery.SchemaField('Time','STRING'),\n",
    "        bigquery.SchemaField('tm1_play', 'STRING'),\n",
    "        bigquery.SchemaField('plus1', 'STRING'),\n",
    "        bigquery.SchemaField('Score', 'STRING'),\n",
    "        bigquery.SchemaField('plus2', 'STRING'),\n",
    "        bigquery.SchemaField('tm2_play', 'STRING'),\n",
    "        bigquery.SchemaField('tm1_players', 'STRING'),\n",
    "        bigquery.SchemaField('tm2_players', 'STRING'),\n",
    "        bigquery.SchemaField('boxscore', 'STRING'),\n",
    "        bigquery.SchemaField('tm1_name', 'STRING'),\n",
    "        bigquery.SchemaField('tm2_name', 'STRING')\n",
    "        ]\n",
    "    \n",
    "    # return out\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition = 'WRITE_TRUNCATE',\n",
    "        schema = schema\n",
    "    )\n",
    "\n",
    "    table_ref = \"dulcet-name-296415.nba_test.pbp_raw\"\n",
    "\n",
    "    job = client.load_table_from_dataframe(out, table_ref, job_config=job_config, location=\"US\")\n",
    "\n",
    "    job.result()  # Waits for table load to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559596e-019c-41df-9b26-5b668721f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "venv_nba",
   "name": "common-cpu.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m82"
  },
  "kernelspec": {
   "display_name": "venv_nba",
   "language": "python",
   "name": "venv_nba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
